---
title             : "Synthesizing an experimental dataset for the evaluation of generic frame detection as a task of detecting communicative intention: Online Appendix"
shorttitle            : "FRAME DETECTION"
floatsintext      : yes
bibliography          : "frame.bib"
output:
 papaja::apa6_pdf:
   latex_engine: xelatex
---

```{r setup, include = FALSE}
library(parameters)
print2 <- function(x, y, r2 = TRUE) {
    cat("## ", x, "\n")
    suppressWarnings(print(print_md(parameters(y, ci = 0.89))))
    if (r2) {
        cat("$R^2$ = ", brms::bayes_R2(y)[1] , "\n\n")
    }
}
ireadRDS <- function(fname) {
    readRDS(here::here("intermediate", fname))
}

require(brms)
require(ggplot2)
require(tidyverse)
require(cowplot)
require(ggridges)

source("lib.R")
```

## Coding scheme (Semetko & Valkenburg)

Attribution of responsibility

* Does the story suggest that some level of government has the ability to alleviate the problem?
* Does the story suggest that some level of the government is responsible for the issue/problem?
* Does the story suggest solution(s) to the problem/issue?
* Does the story suggest that an individual (or group of people in society) is responsible for the issue-problem?
* Does the story suggest the problem requires urgent action?

Human interest frame

* Does the story provide a human example or “human face” on the issue?
* Does the story employ adjectives or personal vignettes that generate feelings of outrage, empathy-caring, sympathy, or compassion?
* Does the story emphasize how individuals and groups are affected by the issue/problem?
* Does the story go into the private or personal lives of the actors?
* ~~Does the story contain visual information that might generate feelings of outrage, empathy-caring, sympathy, or compassion?~~

Conflict frame

* Does the story reflect disagreement between parties/individuals/groups/countries?
* Does one party/individual/group/country reproach another?
* Does the story refer to two sides or to more than two sides of the problem or issue?
* Does the story refer to winners and losers?

Morality frame

* Does the story contain any moral message?
* Does the story make reference to morality, God, and other religious tenets?
* Does the story offer specific social prescriptions about how to behave?

(Economic) consequences frame

* Is there a mention of financial losses or gains now or in the future?
* Is there a mention of the costs/degree of expense involved?
* Is there a reference to economic consequences of pursuing or not pursuing a course of action?

## Overview of all automatic and supervised methods employed

### k-Means

Each document is assigned a vector containing the frequency of each word that occurs in the document (term frequency - TF), weighed against how many documents that word appears in (inverse document frequency - IDF). That way, the term vector is a representation of how documents differ from each other based on how different the words that are used within are. Weighing against inverse document frequency ensures that rare words (which contain more information, e.g. “nuclear”) have more weight than common, generic words (e.g. “man”). Cluster analysis is used to group together documents based on how similar their word vectors are - with k-means clustering, the number of clusters is decided beforehand. Clusters are found by searching for the cluster distribution with the lowest within-cluster sum of squares [@burscher:2014:TCC].

### Principal Component Analysis (PCA)

As above, each document is assigned a vector containing the frequency of each word that occurs in the document (term frequency - TF), weighed against how many documents that word appears in (inverse document frequency - IDF). A TF-IDF can be interpreted as a long list of dimensions in an n-dimensional space. Principal Component Analysis is used to reduce those dimensions by projecting the n-dimensional data onto a space with fewer dimensions (in our case: 5) while maintaining as much variance (and hence: information) as possible. That way, individual word vectors that often occur together will inform the same components in the resulting model. The components can then be interpreted as correlating with Frames [@greussing:2017:S].

### Latent Dirichlet Allocation (LDA)

Topic Modelling assumes that there is a number of topics distributed over the documents you analyze. Topics are expressed through co-occurrence of common vocabulary (e.g.: an “economy” topic would be expressed through words like “costs”, “inflation” etc.). Latent Dirichlet Allocation follows this intuition and tries to allocate words into topics such that both for each document, the words are allocated to as few topics as possible and that for few and rare words, higher topic probabilities are assigned than to common terms. From a Bayesian perspective, each document is assigned topic probabilities for a pre-set number of topics using a hierarchical probabilistic model. The resulting probabilities represent commonly co-occuring terms, which are interpreted as representing common topics of documents [@dimaggio:2013:E].

### Structural Topic Model (STM)

Uses a similar approach to LDA, described above, but allows for using metadata that covaries with topics and allows for topics that correlate with each other [@nicholls:2020:CIM].

### Analysis of Topic Model Networks (ANTMN) 

LDA topic modelling is applied (see above). The number of topics is optimized based on commonly used indicators to assess topic quality. Then, co-occurence of topics is used to generate a topic model network: topics are treated as nodes, their theta-cosine similarity is treated as edges between nodes. Network community detection algorithms are used to combine topics into larger topic communities based on this similarity-network, which are interpreted as representing frames [@walter:2019:NFA].

### Seeded-LDA 

Employs LDA topic modelling (see above), but the researcher applies seed terms derived from theory to guide the topic modelling process: Each seed provided by the researcher is given a prior weight towards topics. The LDA model then assigns topics to documents taking these prior weights into account [@watanabe:2020:TDA].

### Keyword Assisted Topic Model (keyATM) 

Similar to seeded-LDA [@eshima2020keyatm].

## Multiverse analysis of all methods (based on the ground truth)

These figures display the multiverse analyses of human coding (Figure \@ref(fig:human)), K-Means + TF-IDF (Figure \@ref(fig:km)), PCA + TF-IDF (Figure \@ref(fig:pca)), LDA (Figure \@ref(fig:lda)), STM (Figure \@ref(fig:stm)), ANTMN (Figure \@ref(fig:antmn)), seeded LDA (Figure \@ref(fig:seeded)), and KeyATM (Figure \@ref(fig:keyatm)). These figures display the analyses using the original 100-article corpus (green dots) and the corpus without the Morality articles (orange dots).

```{r human, fig.cap = "Multiverse analysis of human coding"}
bind_rows(ireadRDS("expert_accuracy_k4.RDS"), ireadRDS("human_accuracy_k4.RDS")) %>% mutate(expert = c(rep(TRUE, 7), rep(FALSE, 5))) %>% pull(maxp) -> k4_p

bind_rows(ireadRDS("expert_accuracy.RDS"), ireadRDS("human_accuracy.RDS")) %>% mutate(expert = c(rep(TRUE, 7), rep(FALSE, 5))) %>% mutate(maxp2 = k4_p) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% mutate(desc = reorder(desc, ccr)) %>% ggplot(aes(y = reorder(desc, ccr), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r km, fig.cap = "Multiverse analysis of K-Means"}
set.seed(1212121)
frame_df <- rio::import(here::here("data", "Frame Corpus.xlsx")) %>% tibble::as_tibble()
frame_corpus <- corpus(x = frame_df$Content, docnames = frame_df$docid, docvars = data.frame(frame = frame_df$frame))

.gen_no_m_res <- function(prefix, p_is_hat_y = FALSE) {
    p <- readRDS(ipath(paste0(prefix, "_p.RDS")))
    hat_y <- purrr::map(p, .get_hat_y, p_is_hat_y = p_is_hat_y)
    purrr::map(hat_y, .match_topics_no_moral, frame_corpus = frame_corpus)
}

prefix <- "KM"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix, p_is_hat_y = TRUE)) %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""))) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r pca, fig.cap = "Multiverse analysis of PCA"}
prefix <- "PCA"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix, p_is_hat_y = FALSE)) %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""))) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r lda, fig.cap = "Multiverse analysis of LDA", fig.height = 8}
prefix <- "LDA"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix))  %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha)) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1)  + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r stm, fig.cap = "Multiverse analysis of STM", fig.height = 8}
prefix <- "STM"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix))  %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha)) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r antmn, fig.cap = "Multiverse analysis of ANTMN", fig.height = 8}
prefix <- "ANTMN"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix, p_is_hat_y = FALSE)) %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha, ", kf: ", k_factor)) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r seeded, fig.cap = "Multiverse analysis of seeded-LDA", fig.height = 8}
prefix <- "KEYATM"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix, p_is_hat_y = FALSE)) %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", alpha: ", alpha, ", exp", expert)) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

```{r keyatm, fig.cap = "Multiverse analysis of keyATM", fig.height = 8}
prefix <- "SEEDED"
mutate(readRDS(ipath(paste0(prefix, ".RDS"))), no_m_res = .gen_no_m_res(prefix, p_is_hat_y = FALSE)) %>% mutate(maxp = purrr::map_dbl(res, max), maxp2 = purrr::map_dbl(no_m_res, max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", alpha: ", alpha, ", exp", expert)) %>% select(desc, maxp, maxp2) %>% pivot_longer(!desc, names_to = "x", values_to = "ccr") %>% ggplot(aes(y = fct_reorder2(desc, x, ccr, .desc = FALSE), x = ccr, color = x)) + geom_point() + xlim(0, 1) + geom_vline(aes(xintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.3, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed", col = "red") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed", col = "red") + xlab(expression(CCR[max])) + ylab("Treatment") + scale_color_brewer(palette="Dark2") +  theme_minimal() + theme(legend.position = "none")
```

### Visualization of the variance

The variance of $CCR_{max}$ is displayed in Figure \@ref(fig:variance).

```{r variance, message = FALSE, echo = FALSE, fig.cap = "Variance of the best case correct classification rates"}
ireadRDS <- function(fname) {
    readRDS(here::here("intermediate", fname))
}

bind_rows(mutate(ireadRDS("KM.RDS"), method = "K-Means"),
          mutate(ireadRDS("PCA.RDS"), method = "PCA"),
          mutate(ireadRDS("LDA.RDS"), method = "LDA"),
          mutate(ireadRDS("STM.RDS"), method = "STM"),
          mutate(ireadRDS("ANTMN.RDS"), method = "ANTMN"),
          mutate(ireadRDS("SEEDED.RDS"), method = "Seeded LDA"),
          mutate(ireadRDS("KEYATM.RDS"), method = "keyATM")) %>%
    mutate(maxp = map_dbl(res, max)) %>% mutate(method = factor(method)) %>% mutate(method = fct_relevel(method, "K-Means")) -> all_uni

human <- ireadRDS("human_accuracy.RDS") %>% mutate(method = "Gold")

all_uni %>% bind_rows(human) %>% mutate(method_type = case_when(method == "Gold" ~ 0,
                           method %in% c("keyATM", "Seeded LDA") ~ 1,
                           TRUE ~ 2)) %>% mutate(method_type = factor(method_type, levels = c(0,1,2), labels = c("Gold", "Semisupervised", "Automatic"))) -> all_uni
##var(all_uni$maxp[all_uni$method_type == "Automatic"])
##var(all_uni$maxp[all_uni$method_type == "Semisupervised"])

all_uni %>% filter(!method_type %in% c("Gold")) %>% ggplot(aes(y = maxp, x = method)) + geom_dotplot(binaxis='y', stackdir='center', dotsize=0.2) + facet_grid(cols = vars(method_type), scales = "free_x") + theme_minimal() + theme(legend.position = "none") + ylab(expression(CCR[max]))
```

### Sensitivity analysis: Without Morality articles

We retested H1 without all Morality articles (Figure \@ref(fig:sen1) ). H1 appears to be less supported when all Morality articles are removed.

```{r sen1, fig.cap = "Distribution of best-case correct classification rates by methods (without Morality articles)", cache = TRUE}
require(tidyverse)
require(ggridges)


ireadRDS <- function(fname) {
        readRDS(here::here("intermediate", fname))
}


bind_rows(mutate(ireadRDS("KM.RDS"), method = "K-Means", no_m_res = .gen_no_m_res("KM", p_is_hat_y = TRUE)),
              mutate(ireadRDS("PCA.RDS"), method = "PCA", no_m_res = .gen_no_m_res("PCA", p_is_hat_y = FALSE)),
              mutate(ireadRDS("LDA.RDS"), method = "LDA", no_m_res = .gen_no_m_res("LDA", p_is_hat_y = FALSE)),
              mutate(ireadRDS("STM.RDS"), method = "STM", no_m_res = .gen_no_m_res("STM", p_is_hat_y = FALSE)),
              mutate(ireadRDS("ANTMN.RDS"), method = "ANTMN", no_m_res = .gen_no_m_res("ANTMN", p_is_hat_y = FALSE)),
              mutate(ireadRDS("SEEDED.RDS"), method = "Seeded LDA", no_m_res = .gen_no_m_res("SEEDED", p_is_hat_y = FALSE)),
          mutate(ireadRDS("KEYATM.RDS"), method = "keyATM", no_m_res = .gen_no_m_res("KEYATM", p_is_hat_y = FALSE))) -> res

ireadRDS("human_accuracy_k4.RDS")%>% mutate(method = "Gold") %>% select(-desc) -> human

res %>% mutate(maxp = map_dbl(no_m_res, max)) %>% bind_rows(human) %>% mutate(method_type = case_when(method == "Gold" ~ 0,
                               method %in% c("keyATM", "Seeded LDA") ~ 1,
                               TRUE ~ 2)) %>% mutate(method_type = factor(method_type, levels = c(0,1,2), labels = c("Gold", "Semisupervised", "Automatic"))) -> all_uni

all_uni$recommend <- FALSE

all_uni[all_uni$method == "ANTMN" & all_uni$words == "none" & all_uni$trim & all_uni$stopwords,]$recommend <- TRUE

all_uni %>% mutate(method = fct_relevel(method, "Gold", "Seeded LDA", "keyATM")) %>% ggplot(aes(x = maxp, y = method, fill = method_type)) + geom_density_ridges(alpha = 0.5, panel_scaling = TRUE, linetype = "blank")+ geom_density_ridges(aes(point_color = recommend), jittered_points = TRUE, position = position_points_jitter(width = 0.05, height = 0), point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0, panel_scaling = TRUE, linetype = "blank") + geom_vline(aes(xintercept = 0.29, alpha = 0.5), linetype = "dashed") + geom_vline(aes(xintercept = 0.25, alpha = 0.5), linetype = "dashed") + xlim(c(0, 0.7)) + xlab(expression(CCR[max])) + ylab("Method") + theme_minimal() + scale_discrete_manual("point_color", values = c("#B0B0B0", "#FF0000"), guide = "none") + theme(legend.position = "none")
```

## Multiverse analysis of all methods (based on correlation)

The calculation of $CCR_{max}$ makes an assumption that a method can extra a dominant frame. But in fact, most of the methods under consideration can extra multiple "frames" (with the exception of K-Means and the exclusionary item "F1" by the experts). For instance, an LDA model can export for each article a vector of five numbers, $\theta_{t}$. the calculation of $CCR_{max}$ select the highest number among these five numbers as the dominant frame. However, it is possible that the second highest $\theta_{t}$ might match the ground truth. But $CCR_{max}$ does not consider this information.

We vectorize the output $100 \times 5$ matrix $\mathbf{P}$ by stacking the columns of $\mathbf{P}$ on top of one another, i.e.

$$
\operatorname{vec}(\mathbf{P}) = [p_{1,1}, \ldots, p_{100,1}, p_{1,2}, \ldots, p_{100,2}, \ldots, p_{1,5}, \ldots, p_{100,5}]^\mathrm{T}
$$

Another way to evaluate the accuracy is to calculate the correlation between two vectorized $\mathbf{P}$ (each with a dimension of $1 \times 500$). The ground truth vector $y$ can be first matricized as a one-hot matrix and vectorized the same way to generate the same $1 \times 500$ vector. For instance:

$$
y = [1, 2, 3, 1, \ldots, 5]
$$

$$
\operatorname{mat}(y) = \begin{bmatrix}
1 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0\\
1 & 0 & 0 & 0 & 0\\
\vdots & \vdots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & 0 & 1
\end{bmatrix}
$$

Using this approach, we encountered the same problem of not knowing which column in $\mathbf{P}$ corresponds to which actual frame in the ground truth $y$. The same approach of exhaustive search was used and the maximum value of correlation was reported.

These figures display the multiverse analyses of human coding (Figure \@ref(fig:human)), PCA + TF-IDF (Figure \@ref(fig:taupca)), LDA (Figure \@ref(fig:taulda)), STM (Figure \@ref(fig:taustm)), ANTMN (Figure \@ref(fig:tauantmn)), seeded LDA (Figure \@ref(fig:tauseeded)), and KeyATM (Figure \@ref(fig:taukeyatm)). These figures display the analyses using the ground truth (green dots) and the expert coding (orange dots, averaged of the two experts).

```{r tauhuman, fig.cap = "Multiverse analysis of human coding based on correlation"}
prefix <- "human"
ireadRDS(paste0(prefix, "_tau.RDS")) %>% mutate(tau_gt = ireadRDS(paste0(prefix, "_tau_gt.RDS"))$tau) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 1) + theme_minimal() + xlab("r") + ylab("Treatment")+ theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r taupca, fig.cap = "Multiverse analysis of PCA based on correlation"}
prefix <- "PCA"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""))) %>% select(desc, tau, tau_gt) %>% ungroup() %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment") + theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r taustm, fig.cap = "Multiverse analysis of STM based on correlation"}
prefix <- "STM"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha)) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment") + theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r taulda, fig.cap = "Multiverse analysis of LDA based on correlation"}
prefix <- "LDA"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha)) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment") + theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r tauantmn, fig.cap = "Multiverse analysis of ANTMN based on correlation", fig.height = 8}
prefix <- "ANTMN"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", Alpha: ", alpha, ", kf: ", k_factor)) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment")+ theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r tauseeded, fig.cap = "Multiverse analysis of seeded-LDA based on correlation", fig.height = 8}
prefix <- "SEEDED"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", alpha: ", alpha, ", exp", expert)) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment")+ theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

```{r taukeyatm, fig.cap = "Multiverse analysis of keyATM based on correlation", fig.height = 8}
prefix <- "KEYATM"

mutate(ireadRDS(paste0(prefix, ".RDS")), tau = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau.RDS")), max), tau_gt  = purrr::map_dbl(ireadRDS(paste0(prefix, "_tau_gt.RDS")), max)) %>% rowwise() %>% mutate(desc = paste0(words, ifelse(stopwords, ", sw", ""), ifelse(trim, ", s/d", ""), ", alpha: ", alpha, ", exp", expert)) %>% select(desc, tau, tau_gt) %>% pivot_longer(!desc, names_to = "x", values_to = "tau") %>% ggplot(aes(y = fct_reorder2(desc, x, tau, .desc = FALSE), x = tau, color = x)) + geom_point() + xlim(0, 0.5) + theme_minimal() + xlab("r") + ylab("Treatment")+ theme(legend.position = "none") + scale_color_brewer(palette="Dark2")
```

### Sensitivity analysis: With correlation, using ground truth

We retested H1 with correlation and ground truth (Figure \@ref(fig:sen2) ). H1 appears to be similarly supported.

```{r sen2, fig.cap = "Distribution of correlation by methods (using ground truth)", cache = TRUE}
require(tidyverse)
require(ggridges)


ireadRDS <- function(fname) {
        readRDS(here::here("intermediate", fname))
}


bind_rows(mutate(ireadRDS("PCA.RDS"), method = "PCA", tau = purrr::map_dbl(ireadRDS("PCA_tau_gt.RDS"), max)),
          mutate(ireadRDS("LDA.RDS"), method = "LDA", tau = purrr::map_dbl(ireadRDS("LDA_tau_gt.RDS"), max)),
          mutate(ireadRDS("STM.RDS"), method = "STM", tau  = purrr::map_dbl(ireadRDS("STM_tau_gt.RDS"), max)),
          mutate(ireadRDS("ANTMN.RDS"), method = "ANTMN", tau  = purrr::map_dbl(ireadRDS("ANTMN_tau_gt.RDS"), max)),
          mutate(ireadRDS("SEEDED.RDS"), method = "Seeded LDA", tau  = purrr::map_dbl(ireadRDS("SEEDED_tau_gt.RDS"), max)),
          mutate(ireadRDS("KEYATM.RDS"), method = "keyATM", tau  = purrr::map_dbl(ireadRDS("KEYATM_tau_gt.RDS"), max))) -> res

prefix <- "human"
ireadRDS(paste0(prefix, "_tau_gt.RDS")) %>% mutate(method = "Gold") %>% select(-desc) -> human

res  %>% bind_rows(human) %>% mutate(method_type = case_when(method == "Gold" ~ 0,
                               method %in% c("keyATM", "Seeded LDA") ~ 1,
                               TRUE ~ 2)) %>% mutate(method_type = factor(method_type, levels = c(0,1,2), labels = c("Gold", "Semisupervised", "Automatic"))) -> all_uni

all_uni$recommend <- FALSE

all_uni[all_uni$method == "ANTMN" & all_uni$words == "none" & all_uni$trim & all_uni$stopwords,]$recommend <- TRUE


all_uni %>% mutate(method = fct_relevel(method, "Gold", "Seeded LDA", "keyATM")) %>% ggplot(aes(x = tau, y = method, fill = method_type)) + geom_density_ridges(alpha = 0.5, panel_scaling = TRUE, linetype = "blank")+ geom_density_ridges(aes(point_color = recommend), jittered_points = TRUE, position = position_points_jitter(width = 0.05, height = 0), point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0, panel_scaling = TRUE, linetype = "blank") + xlim(c(0, 0.5)) + xlab("R") + ylab("Method") + theme_minimal() + scale_discrete_manual("point_color", values = c("#B0B0B0", "#FF0000"), guide = "none") + theme(legend.position = "none")
```

### Sensitivity analysis: With correlation, using expert coding

We retested H1 with correlation and expert coding (Figure \@ref(fig:sen3) ). H1 appears to be similarly supported. Please note that this is not a task of detecting communicative intention.

```{r sen3, fig.cap = "Distribution of correlation by methods (using expert coding)", cache = TRUE}
require(tidyverse)
require(ggridges)


ireadRDS <- function(fname) {
        readRDS(here::here("intermediate", fname))
}


bind_rows(mutate(ireadRDS("PCA.RDS"), method = "PCA", tau = purrr::map_dbl(ireadRDS("PCA_tau.RDS"), max)),
          mutate(ireadRDS("LDA.RDS"), method = "LDA", tau = purrr::map_dbl(ireadRDS("LDA_tau.RDS"), max)),
          mutate(ireadRDS("STM.RDS"), method = "STM", tau  = purrr::map_dbl(ireadRDS("STM_tau.RDS"), max)),
          mutate(ireadRDS("ANTMN.RDS"), method = "ANTMN", tau  = purrr::map_dbl(ireadRDS("ANTMN_tau.RDS"), max)),
          mutate(ireadRDS("SEEDED.RDS"), method = "Seeded LDA", tau  = purrr::map_dbl(ireadRDS("SEEDED_tau.RDS"), max)),
          mutate(ireadRDS("KEYATM.RDS"), method = "keyATM", tau  = purrr::map_dbl(ireadRDS("KEYATM_tau.RDS"), max))) -> res

prefix <- "human"
ireadRDS(paste0(prefix, "_tau.RDS")) %>% mutate(method = "Gold") %>% select(-desc) -> human

res  %>% bind_rows(human) %>% mutate(method_type = case_when(method == "Gold" ~ 0,
                               method %in% c("keyATM", "Seeded LDA") ~ 1,
                               TRUE ~ 2)) %>% mutate(method_type = factor(method_type, levels = c(0,1,2), labels = c("Gold", "Semisupervised", "Automatic"))) -> all_uni

all_uni$recommend <- FALSE

all_uni[all_uni$method == "ANTMN" & all_uni$words == "none" & all_uni$trim & all_uni$stopwords,]$recommend <- TRUE

all_uni %>% mutate(method = fct_relevel(method, "Gold", "Seeded LDA", "keyATM")) %>% ggplot(aes(x = tau, y = method, fill = method_type)) + geom_density_ridges(alpha = 0.5, panel_scaling = TRUE, linetype = "blank")+ geom_density_ridges(aes(point_color = recommend), jittered_points = TRUE, position = position_points_jitter(width = 0.05, height = 0), point_shape = '|', point_size = 3, point_alpha = 1, alpha = 0, panel_scaling = TRUE, linetype = "blank") + xlim(c(0, 1)) + xlab("R") + ylab("Method") + theme_minimal() + scale_discrete_manual("point_color", values = c("#B0B0B0", "#FF0000"), guide = "none") + theme(legend.position = "none")
```

## Comparing confidence level of correct and incorrect expert coding

We modeled the correctness of expert coding ("F1" is equal to the ground truth) and confidence level ("F2"), while adjusting for individual differences between the two experts using Bayesian multilevel logistic regression analysis. The following is the robust conditional effect plot. There is no evidence to suggest that there is a trend. Therefore, experts can either confidently give correct and incorrect coding.

```{r brms1, fig.cap = "Robust conditional effects from the Bayesian model on the relationship between correction rate of expert coding"}
mod <- readRDS(here::here("intermediate/conf_mod.RDS"))
plot(conditional_effects(mod, prob = 1, plot = FALSE), plot = FALSE) [[1]] +  xlab("Confidence") + ylab("Correction rate") + theme_minimal()
```

## Simulation of increasing sample size

In this analysis, we simulated the possible outcome of increasing the sample size on the multiverse analysis.

From our 100 articles, we created further synthetic articles following the principle of bootstrapping. We synthesized more articles based on the following algorithm:

1. Randomly select one article
2. Tokenize this article into its *n* sentences
3. From these *n* sentences, randomly draw *n* sentences from these sentences with replacement. Therefore, one sentence can appear more than once.
4. Concatenate these randomly drawn *n* sentences into a synthetic article, assign this article with the same topic and frame as the original article

We repeat the above process for 500, 1000, and 2000 times to generate 3 different corpora. This approach is compatible with the bag-of-words representation used in all unsupervised and semi-supervised methods because the word order is not considered. Also in step 3, topical and frame clues have the same natural chance of being selected. To put this simulation in another perspective, it simulates whether frames, rather than topics, are more likely to be picked up by these unsupervised and semi-supervised methods when the sample size increases.

```{r sim1, fig.cap = "Multiverse analyses with different sample sizes: 500, 1000, 2000"}
ns <- c(500, 1000, 2000)
sreadRDS <- function(method, n) {
    readRDS(here::here("intermediate/sim", paste0(method, "_sim", n, ".RDS")))
}

plotn <- function(method, n) {
    sreadRDS(method, n) %>% mutate(maxp = map_dbl(res, max)) -> ldax
    return(data.frame(x = seq(1, nrow(ldax)), method = method, n = n, maxp = sort(ldax$maxp)))
}

methods <- c("KM", "PCA", "LDA", "STM", "ANTMN", "SEEDED", "KEYATM")
conditions <- expand.grid(ns, methods)

purrr::map2_dfr(conditions$Var2, conditions$Var1, plotn) %>% mutate(n = factor(n, levels = ns)) %>% ggplot(aes(x = maxp, y = x, group = n, color = n)) + geom_line() + geom_vline(aes(xintercept = 0.2), alpha = 0.5, linetype = "dashed") + geom_vline(aes(xintercept = 0.3), alpha = 0.5, linetype = "dashed") + xlab(expression(CCR[max])) + xlim(0, 0.6) + ylab("Treatment") + facet_wrap(facets = vars(method), nrow = 3, scales = "free_y") + theme_minimal()
```

The above figure shows the sorted $CCR_{max}$ like the visualization of multiverse in the main text. All confidence intervals have been stripped for clarity as we are only interested in the point estimate. The treatments are the same as the main analysis and they are not displayed in the y-axes.

From this simulation, it is extremely unlikely that increasing the sample size would increase the $CCR_{max}$ for all unsupervised methods. Instead, all methods, except KM and STM, perform more like the de-facto null (0.3) with the increasing sample size. Therefore, these methods appear to be more keen to pick up **topics**, rather than frames, when sample size increases: the sorted performance curve rescinding towards the null value with the highest sample size. For the two semi-supervised methods, increasing the sample size appears to provide better resistance against the rescinding.

<!-- We also performed the same Bayesian analysis using the simulated data. By increasing the sample size, it appears that both H1 and H2 would become more significant, instead of the other way around. -->

<!-- ```{r simbrms, fig.cap = "Robust conditional effects from the Bayesian model of the \"gold standard\", semi-supervised and automatic methods at 89% credibility with different simulated sample sizes"} -->
<!-- p1 <- plot(conditional_effects(readRDS("intermediate/sim/brms_mod_sim500.RDS"), prob = 0.89), plot = FALSE)[[1]] + coord_flip() + geom_hline(aes(yintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_hline(aes(yintercept = 0.3, alpha = 0.5), linetype = "dashed") +  ylab(expression(CCR[max])) + xlab("Method type") + theme_minimal() + theme(legend.position = "none") -->
<!-- p2 <- plot(conditional_effects(readRDS("intermediate/sim/brms_mod_sim1000.RDS"), prob = 0.89), plot = FALSE)[[1]] + coord_flip() + geom_hline(aes(yintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_hline(aes(yintercept = 0.3, alpha = 0.5), linetype = "dashed") +  ylab(expression(CCR[max])) + xlab("Method type") + theme_minimal() + theme(legend.position = "none") -->
<!-- p3 <- plot(conditional_effects(readRDS("intermediate/sim/brms_mod_sim2000.RDS"), prob = 0.89), plot = FALSE)[[1]] + coord_flip() + geom_hline(aes(yintercept = 0.2, alpha = 0.5), linetype = "dashed") + geom_hline(aes(yintercept = 0.3, alpha = 0.5), linetype = "dashed") +  ylab(expression(CCR[max])) + xlab("Method type") + theme_minimal() + theme(legend.position = "none") -->
<!-- plot_grid(p1, p2, p3, labels = c('500', '1000', '2000'), ncol = 1) -->
<!-- ``` -->

<!-- ## Regression coefficients of the Bayesian model -->

<!-- ```{r, results = "asis", echo = FALSE} -->
<!-- print2("", readRDS(here::here("intermediate", "brms_mod.RDS"))) -->
<!-- ``` -->

# References


\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}


<div id="refs" custom-style="Bibliography"></div>
\endgroup
